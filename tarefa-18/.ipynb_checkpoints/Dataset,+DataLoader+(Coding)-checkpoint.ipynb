{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veP8EzgbdBXW"
   },
   "source": [
    "# Batch Size: Batch size refers to the number of data points considered to calculate the loss value or update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4816,
     "status": "ok",
     "timestamp": 1684393075028,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "czzdEJW6dDLJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCp2eqAzdRh9"
   },
   "source": [
    "# Define the same dataset as in the previous lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1163,
     "status": "ok",
     "timestamp": 1684393106599,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "odDKbk1VdKH9"
   },
   "outputs": [],
   "source": [
    "x = [[1,2],[3,4],[5,6],[7,8]]\n",
    "y = [[3],[7],[11],[15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684393112805,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "xA9vhkghdOwk"
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(x).float()\n",
    "Y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684393113416,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "0huGxSDEcyFY"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQGJO8m-eA48"
   },
   "source": [
    "In the MyDataset class, we hold the necessary details for retrieving individual data points, allowing us to group them into batches (using DataLoader) and process them together in a single forward and back-propagation step to update the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y1hWLKueWrj"
   },
   "source": [
    "# Theser are 3 main things you need to remember\n",
    "## 1) Inherit from Dataset class and implement __init__ method\n",
    "## 2) Implement __getitem__ method (Whatever this method returns is what we get when we create a dataloader)\n",
    "## 3) Implement __len__ method\n",
    "## These 3 functions are a necessity, there is also a collate_fn which I would cover in the future lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1684393119492,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "LjIe9yMgeI2k"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x).float().to(device)\n",
    "    self.y = torch.tensor(y).float().to(device)\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "  def __getitem__(self,ix):\n",
    "    return self.x[ix], self.y[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684393121069,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "f8sbc1SteBW9"
   },
   "outputs": [],
   "source": [
    "ds = MyDataset(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95PsnktTf6Cb"
   },
   "source": [
    "# Dataloader object is used to load data from a dataset and return it in the form of mini-batches. It provides an iterable over the dataset, with support for multi-process data loading and customizable data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1684393122340,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "US8B13-0f0PH"
   },
   "outputs": [],
   "source": [
    "# Notice Batch size\n",
    "dl = DataLoader(ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682360545175,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "1xhaoA1Jf5Bf",
    "outputId": "dc0af16b-11a0-4fa7-d64e-e892a3486f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.],\n",
      "        [1., 2.]]) tensor([[11.],\n",
      "        [ 3.]])\n",
      "tensor([[3., 4.],\n",
      "        [7., 8.]]) tensor([[ 7.],\n",
      "        [15.]])\n"
     ]
    }
   ],
   "source": [
    "# To load the data we loop through it\n",
    "for x,y in dl:\n",
    "  print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFFAMefsgKiT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tee4vhKgi4Z"
   },
   "source": [
    "# Using the DataLoader object in the training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684393134122,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "4B2snffDgz1C"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEZyuQz7qx8E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684393135306,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "zluQiZ0Xgl9q"
   },
   "outputs": [],
   "source": [
    "class MyNeuralNet(nn.Module):\n",
    "  def __init__(self):  \n",
    "    # When we call the super.__init__() method we ensure we are inhertiting   \n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(2,8) # A linear layer\n",
    "    self.activation = nn.ReLU() # activation function\n",
    "    self.layer2 =  nn.Linear(8,1)\n",
    "\n",
    "  # When we pass something through the model object, it calls the forward function \n",
    "  def forward(self,x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.activation(x)\n",
    "    x = self.layer2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1684393146765,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "UpYP8hHYgrxN"
   },
   "outputs": [],
   "source": [
    "model = MyNeuralNet()\n",
    "loss_func = nn.MSELoss()\n",
    "opt = SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1684393150803,
     "user": {
      "displayName": "Sahil Sheikh",
      "userId": "07547610742251332939"
     },
     "user_tz": -330
    },
    "id": "JQYdZSYIgvuL"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(50): #Running for 50 epochs\n",
    "  for data in dl:\n",
    "    opt.zero_grad() # Setting gradients to zero before every epoch\n",
    "    x1, y1 = data\n",
    "    loss_value = loss_func(model(x1),y1)\n",
    "    #  the gradients of the loss function with respect to all the trainable parameters of the network are computed and stored in the grad attribute of the corresponding tensors.\n",
    "    loss_value.backward()\n",
    "\n",
    "    # opt.step() is to update the weights and biases of the neural network using the computed gradients and the chosen optimization algorithm\n",
    "    opt.step() \n",
    "    losses.append(loss_value.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIRtHheFhH0Q"
   },
   "source": [
    "# By using a dataloader object we are able to train the model much faster, as batch processing is taking place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGT6ZLY2c0dV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzDFW7jz1KD4XqjRYt0+a7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
