{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d5a5d00-282e-4721-9231-5c067ee4ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681c610a-ffe8-4813-b5ee-6de87859b1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "43/43 [==============================] - 2s 16ms/step - loss: 0.6246 - accuracy: 0.7582 - val_loss: 0.6871 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8920 - val_loss: 0.6890 - val_accuracy: 0.4615\n",
      "Epoch 3/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8944 - val_loss: 0.6181 - val_accuracy: 0.6014\n",
      "Epoch 4/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2284 - accuracy: 0.9061 - val_loss: 0.4096 - val_accuracy: 0.8182\n",
      "Epoch 5/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.2344 - accuracy: 0.8944 - val_loss: 0.2952 - val_accuracy: 0.8741\n",
      "Epoch 6/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.2171 - accuracy: 0.9272 - val_loss: 0.2285 - val_accuracy: 0.9161\n",
      "Epoch 7/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.8967 - val_loss: 0.2023 - val_accuracy: 0.9301\n",
      "Epoch 8/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9131 - val_loss: 0.1954 - val_accuracy: 0.9301\n",
      "Epoch 9/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2032 - accuracy: 0.9366 - val_loss: 0.1884 - val_accuracy: 0.9371\n",
      "Epoch 10/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.9108 - val_loss: 0.1919 - val_accuracy: 0.9161\n",
      "Epoch 11/150\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.1978 - accuracy: 0.9178 - val_loss: 0.1980 - val_accuracy: 0.9161\n",
      "Epoch 12/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9437 - val_loss: 0.1833 - val_accuracy: 0.9161\n",
      "Epoch 13/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9014 - val_loss: 0.1945 - val_accuracy: 0.9161\n",
      "Epoch 14/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2113 - accuracy: 0.9202 - val_loss: 0.1957 - val_accuracy: 0.9091\n",
      "Epoch 15/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1550 - accuracy: 0.9484 - val_loss: 0.2069 - val_accuracy: 0.9021\n",
      "Epoch 16/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.2307 - accuracy: 0.9061 - val_loss: 0.2091 - val_accuracy: 0.9021\n",
      "Epoch 17/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.2169 - accuracy: 0.9131 - val_loss: 0.2068 - val_accuracy: 0.9161\n",
      "Epoch 18/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2614 - accuracy: 0.9108 - val_loss: 0.2017 - val_accuracy: 0.9231\n",
      "Epoch 19/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9484 - val_loss: 0.2008 - val_accuracy: 0.9231\n",
      "Epoch 20/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9249 - val_loss: 0.2032 - val_accuracy: 0.9161\n",
      "Epoch 21/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9390 - val_loss: 0.2020 - val_accuracy: 0.9161\n",
      "Epoch 22/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2107 - accuracy: 0.9061 - val_loss: 0.1966 - val_accuracy: 0.9161\n",
      "Epoch 23/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2087 - accuracy: 0.9319 - val_loss: 0.1973 - val_accuracy: 0.9021\n",
      "Epoch 24/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2135 - accuracy: 0.9272 - val_loss: 0.1908 - val_accuracy: 0.9091\n",
      "Epoch 25/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2167 - accuracy: 0.9131 - val_loss: 0.1972 - val_accuracy: 0.9021\n",
      "Epoch 26/150\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.1839 - accuracy: 0.9272 - val_loss: 0.2001 - val_accuracy: 0.9091\n",
      "Epoch 27/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1649 - accuracy: 0.9343 - val_loss: 0.1945 - val_accuracy: 0.9091\n",
      "Epoch 28/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2061 - accuracy: 0.9131 - val_loss: 0.2000 - val_accuracy: 0.9091\n",
      "Epoch 29/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9272 - val_loss: 0.1894 - val_accuracy: 0.9161\n",
      "Epoch 30/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9366 - val_loss: 0.1900 - val_accuracy: 0.9091\n",
      "Epoch 31/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9108 - val_loss: 0.1890 - val_accuracy: 0.9231\n",
      "Epoch 32/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9178 - val_loss: 0.1872 - val_accuracy: 0.9231\n",
      "Epoch 33/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9178 - val_loss: 0.1895 - val_accuracy: 0.9161\n",
      "Epoch 34/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2074 - accuracy: 0.9202 - val_loss: 0.1839 - val_accuracy: 0.9231\n",
      "Epoch 35/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9155 - val_loss: 0.1858 - val_accuracy: 0.9301\n",
      "Epoch 36/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1714 - accuracy: 0.9460 - val_loss: 0.1880 - val_accuracy: 0.9231\n",
      "Epoch 37/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2432 - accuracy: 0.9061 - val_loss: 0.1900 - val_accuracy: 0.9301\n",
      "Epoch 38/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9319 - val_loss: 0.1937 - val_accuracy: 0.9301\n",
      "Epoch 39/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.1949 - accuracy: 0.9319 - val_loss: 0.1986 - val_accuracy: 0.9231\n",
      "Epoch 40/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1673 - accuracy: 0.9437 - val_loss: 0.1941 - val_accuracy: 0.9231\n",
      "Epoch 41/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9366 - val_loss: 0.1977 - val_accuracy: 0.9231\n",
      "Epoch 42/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1667 - accuracy: 0.9484 - val_loss: 0.2020 - val_accuracy: 0.9231\n",
      "Epoch 43/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2565 - accuracy: 0.8967 - val_loss: 0.2087 - val_accuracy: 0.9301\n",
      "Epoch 44/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9413 - val_loss: 0.2134 - val_accuracy: 0.9021\n",
      "Epoch 45/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.9366 - val_loss: 0.2064 - val_accuracy: 0.9091\n",
      "Epoch 46/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9108 - val_loss: 0.1976 - val_accuracy: 0.9091\n",
      "Epoch 47/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2071 - accuracy: 0.9061 - val_loss: 0.1898 - val_accuracy: 0.9161\n",
      "Epoch 48/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9366 - val_loss: 0.2035 - val_accuracy: 0.9161\n",
      "Epoch 49/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.9272 - val_loss: 0.2069 - val_accuracy: 0.9091\n",
      "Epoch 50/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1813 - accuracy: 0.9319 - val_loss: 0.2025 - val_accuracy: 0.9161\n",
      "Epoch 51/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9390 - val_loss: 0.2078 - val_accuracy: 0.9161\n",
      "Epoch 52/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9296 - val_loss: 0.2117 - val_accuracy: 0.9091\n",
      "Epoch 53/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2154 - accuracy: 0.9108 - val_loss: 0.2295 - val_accuracy: 0.9091\n",
      "Epoch 54/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2208 - accuracy: 0.9249 - val_loss: 0.2358 - val_accuracy: 0.9021\n",
      "Epoch 55/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.1812 - accuracy: 0.9249 - val_loss: 0.2341 - val_accuracy: 0.8881\n",
      "Epoch 56/150\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1685 - accuracy: 0.9390 - val_loss: 0.2297 - val_accuracy: 0.9021\n",
      "Epoch 57/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9366 - val_loss: 0.2267 - val_accuracy: 0.9021\n",
      "Epoch 58/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.9390 - val_loss: 0.2285 - val_accuracy: 0.9021\n",
      "Epoch 59/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2525 - accuracy: 0.9108 - val_loss: 0.2341 - val_accuracy: 0.9021\n",
      "Epoch 60/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1804 - accuracy: 0.9366 - val_loss: 0.2454 - val_accuracy: 0.9021\n",
      "Epoch 61/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.2026 - accuracy: 0.9272 - val_loss: 0.2403 - val_accuracy: 0.9091\n",
      "Epoch 62/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1689 - accuracy: 0.9272 - val_loss: 0.2283 - val_accuracy: 0.9231\n",
      "Epoch 63/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9413 - val_loss: 0.2197 - val_accuracy: 0.9161\n",
      "Epoch 64/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9178 - val_loss: 0.2239 - val_accuracy: 0.9091\n",
      "Epoch 65/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2003 - accuracy: 0.9319 - val_loss: 0.2436 - val_accuracy: 0.9091\n",
      "Epoch 66/150\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1900 - accuracy: 0.9343 - val_loss: 0.2375 - val_accuracy: 0.9091\n",
      "Epoch 67/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1621 - accuracy: 0.9366 - val_loss: 0.2364 - val_accuracy: 0.9021\n",
      "Epoch 68/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9366 - val_loss: 0.2466 - val_accuracy: 0.8951\n",
      "Epoch 69/150\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.1525 - accuracy: 0.9460 - val_loss: 0.2559 - val_accuracy: 0.8811\n",
      "Epoch 70/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1707 - accuracy: 0.9366 - val_loss: 0.2479 - val_accuracy: 0.8881\n",
      "Epoch 71/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.1830 - accuracy: 0.9366 - val_loss: 0.2412 - val_accuracy: 0.8881\n",
      "Epoch 72/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9155 - val_loss: 0.2323 - val_accuracy: 0.8951\n",
      "Epoch 73/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1766 - accuracy: 0.9272 - val_loss: 0.2311 - val_accuracy: 0.9021\n",
      "Epoch 74/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.2564 - accuracy: 0.9085 - val_loss: 0.2619 - val_accuracy: 0.9021\n",
      "Epoch 75/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2091 - accuracy: 0.9202 - val_loss: 0.2730 - val_accuracy: 0.8811\n",
      "Epoch 76/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9178 - val_loss: 0.2571 - val_accuracy: 0.8881\n",
      "Epoch 77/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9272 - val_loss: 0.2643 - val_accuracy: 0.8881\n",
      "Epoch 78/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9319 - val_loss: 0.2602 - val_accuracy: 0.9021\n",
      "Epoch 79/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.2029 - accuracy: 0.9343 - val_loss: 0.2669 - val_accuracy: 0.8741\n",
      "Epoch 80/150\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.2014 - accuracy: 0.9178 - val_loss: 0.2506 - val_accuracy: 0.8881\n",
      "Epoch 81/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1708 - accuracy: 0.9437 - val_loss: 0.2528 - val_accuracy: 0.8811\n",
      "Epoch 82/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1521 - accuracy: 0.9413 - val_loss: 0.2649 - val_accuracy: 0.8951\n",
      "Epoch 83/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1597 - accuracy: 0.9507 - val_loss: 0.2581 - val_accuracy: 0.8811\n",
      "Epoch 84/150\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1451 - accuracy: 0.9601 - val_loss: 0.2675 - val_accuracy: 0.8811\n",
      "Epoch 85/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9601 - val_loss: 0.2650 - val_accuracy: 0.8811\n",
      "Epoch 86/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9202 - val_loss: 0.2923 - val_accuracy: 0.8951\n",
      "Epoch 87/150\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1855 - accuracy: 0.9319 - val_loss: 0.2496 - val_accuracy: 0.8951\n",
      "Epoch 88/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1547 - accuracy: 0.9366 - val_loss: 0.2545 - val_accuracy: 0.8811\n",
      "Epoch 89/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9390 - val_loss: 0.2590 - val_accuracy: 0.8811\n",
      "Epoch 90/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1502 - accuracy: 0.9319 - val_loss: 0.2655 - val_accuracy: 0.9021\n",
      "Epoch 91/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9343 - val_loss: 0.2593 - val_accuracy: 0.8951\n",
      "Epoch 92/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1828 - accuracy: 0.9272 - val_loss: 0.2501 - val_accuracy: 0.8881\n",
      "Epoch 93/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1663 - accuracy: 0.9343 - val_loss: 0.2265 - val_accuracy: 0.9021\n",
      "Epoch 94/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1771 - accuracy: 0.9296 - val_loss: 0.2307 - val_accuracy: 0.9091\n",
      "Epoch 95/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1886 - accuracy: 0.9319 - val_loss: 0.2331 - val_accuracy: 0.9021\n",
      "Epoch 96/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1952 - accuracy: 0.9202 - val_loss: 0.2394 - val_accuracy: 0.9091\n",
      "Epoch 97/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1820 - accuracy: 0.9178 - val_loss: 0.2326 - val_accuracy: 0.8881\n",
      "Epoch 98/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1618 - accuracy: 0.9296 - val_loss: 0.2178 - val_accuracy: 0.9021\n",
      "Epoch 99/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1727 - accuracy: 0.9437 - val_loss: 0.2321 - val_accuracy: 0.9021\n",
      "Epoch 100/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9131 - val_loss: 0.2497 - val_accuracy: 0.8811\n",
      "Epoch 101/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9460 - val_loss: 0.2219 - val_accuracy: 0.9091\n",
      "Epoch 102/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1596 - accuracy: 0.9437 - val_loss: 0.2072 - val_accuracy: 0.9091\n",
      "Epoch 103/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2008 - accuracy: 0.9366 - val_loss: 0.2428 - val_accuracy: 0.8951\n",
      "Epoch 104/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1375 - accuracy: 0.9413 - val_loss: 0.2328 - val_accuracy: 0.8951\n",
      "Epoch 105/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1429 - accuracy: 0.9390 - val_loss: 0.2411 - val_accuracy: 0.8951\n",
      "Epoch 106/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2141 - accuracy: 0.9225 - val_loss: 0.2347 - val_accuracy: 0.9021\n",
      "Epoch 107/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2019 - accuracy: 0.9272 - val_loss: 0.2390 - val_accuracy: 0.8881\n",
      "Epoch 108/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9437 - val_loss: 0.2432 - val_accuracy: 0.8951\n",
      "Epoch 109/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9624 - val_loss: 0.2343 - val_accuracy: 0.8951\n",
      "Epoch 110/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1880 - accuracy: 0.9296 - val_loss: 0.2459 - val_accuracy: 0.9021\n",
      "Epoch 111/150\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.1499 - accuracy: 0.9437 - val_loss: 0.2380 - val_accuracy: 0.9091\n",
      "Epoch 112/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9507 - val_loss: 0.2467 - val_accuracy: 0.8951\n",
      "Epoch 113/150\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.1581 - accuracy: 0.9460 - val_loss: 0.2363 - val_accuracy: 0.9021\n",
      "Epoch 114/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1569 - accuracy: 0.9460 - val_loss: 0.2335 - val_accuracy: 0.8951\n",
      "Epoch 115/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1341 - accuracy: 0.9601 - val_loss: 0.2470 - val_accuracy: 0.8951\n",
      "Epoch 116/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.1708 - accuracy: 0.9413 - val_loss: 0.2373 - val_accuracy: 0.8951\n",
      "Epoch 117/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1680 - accuracy: 0.9319 - val_loss: 0.2320 - val_accuracy: 0.9091\n",
      "Epoch 118/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1656 - accuracy: 0.9343 - val_loss: 0.2256 - val_accuracy: 0.9161\n",
      "Epoch 119/150\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9272 - val_loss: 0.2221 - val_accuracy: 0.9091\n",
      "Epoch 120/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9366 - val_loss: 0.2283 - val_accuracy: 0.9021\n",
      "Epoch 121/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.2078 - accuracy: 0.9108 - val_loss: 0.2220 - val_accuracy: 0.9021\n",
      "Epoch 122/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1766 - accuracy: 0.9319 - val_loss: 0.2085 - val_accuracy: 0.9091\n",
      "Epoch 123/150\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.2129 - accuracy: 0.9202 - val_loss: 0.2161 - val_accuracy: 0.8951\n",
      "Epoch 124/150\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1297 - accuracy: 0.9531 - val_loss: 0.2183 - val_accuracy: 0.8951\n",
      "Epoch 125/150\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9437 - val_loss: 0.2263 - val_accuracy: 0.8951\n",
      "Epoch 126/150\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9413 - val_loss: 0.2271 - val_accuracy: 0.8951\n",
      "Epoch 127/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9460 - val_loss: 0.2394 - val_accuracy: 0.8811\n",
      "Epoch 128/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1731 - accuracy: 0.9460 - val_loss: 0.2365 - val_accuracy: 0.8881\n",
      "Epoch 129/150\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.1834 - accuracy: 0.9343 - val_loss: 0.2397 - val_accuracy: 0.8741\n",
      "Epoch 130/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1592 - accuracy: 0.9413 - val_loss: 0.2466 - val_accuracy: 0.8741\n",
      "Epoch 131/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9249 - val_loss: 0.2529 - val_accuracy: 0.8741\n",
      "Epoch 132/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1256 - accuracy: 0.9577 - val_loss: 0.2575 - val_accuracy: 0.8811\n",
      "Epoch 133/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1572 - accuracy: 0.9272 - val_loss: 0.2331 - val_accuracy: 0.8951\n",
      "Epoch 134/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1359 - accuracy: 0.9531 - val_loss: 0.2226 - val_accuracy: 0.8741\n",
      "Epoch 135/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9366 - val_loss: 0.2187 - val_accuracy: 0.8881\n",
      "Epoch 136/150\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 0.1787 - accuracy: 0.9296 - val_loss: 0.2382 - val_accuracy: 0.8811\n",
      "Epoch 137/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.2217 - accuracy: 0.9155 - val_loss: 0.2305 - val_accuracy: 0.8881\n",
      "Epoch 138/150\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.1600 - accuracy: 0.9296 - val_loss: 0.2219 - val_accuracy: 0.8811\n",
      "Epoch 139/150\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1439 - accuracy: 0.9437 - val_loss: 0.2080 - val_accuracy: 0.9021\n",
      "Epoch 140/150\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.1610 - accuracy: 0.9413 - val_loss: 0.2113 - val_accuracy: 0.8951\n",
      "Epoch 141/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1458 - accuracy: 0.9484 - val_loss: 0.2073 - val_accuracy: 0.8951\n",
      "Epoch 142/150\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2205 - accuracy: 0.8920 - val_loss: 0.2050 - val_accuracy: 0.9021\n",
      "Epoch 143/150\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.1670 - accuracy: 0.9366 - val_loss: 0.2185 - val_accuracy: 0.9021\n",
      "Epoch 144/150\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1425 - accuracy: 0.9484 - val_loss: 0.2396 - val_accuracy: 0.8811\n",
      "Epoch 145/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1860 - accuracy: 0.9225 - val_loss: 0.2386 - val_accuracy: 0.8811\n",
      "Epoch 146/150\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9437 - val_loss: 0.2344 - val_accuracy: 0.8811\n",
      "Epoch 147/150\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1498 - accuracy: 0.9343 - val_loss: 0.2175 - val_accuracy: 0.9021\n",
      "Epoch 148/150\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.1765 - accuracy: 0.9343 - val_loss: 0.2280 - val_accuracy: 0.9021\n",
      "Epoch 149/150\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.1342 - accuracy: 0.9531 - val_loss: 0.2537 - val_accuracy: 0.9021\n",
      "Epoch 150/150\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.1394 - accuracy: 0.9484 - val_loss: 0.2576 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13d1a8b8b50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "classificador = Sequential()\n",
    "classificador.add(BatchNormalization(input_shape=(30,)))\n",
    "classificador.add(Dense(units=32, activation='relu', kernel_initializer='random_uniform'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "otimizador = keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5, name=\"adam\", beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=150, validation_data=(previsores_teste, classe_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d33a47-92eb-42e7-b4c4-f451313859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.156028 , 1.0739694, 1.0418284, 0.9916374, 1.1395696, 1.059468 ,\n",
      "       1.092533 , 1.2322474, 1.2035749, 1.1446854, 1.0750293, 1.1011252,\n",
      "       1.1229426, 1.2697929, 1.7060609, 1.0573579, 1.2803793, 1.1870807,\n",
      "       1.3338115, 1.279027 , 0.9942849, 1.1767486, 1.2259401, 1.1257514,\n",
      "       1.1036229, 1.0173341, 1.1783755, 1.0775149, 1.0818685, 1.3215758],\n",
      "      dtype=float32), array([-0.20332837, -0.02599789,  0.12644385,  0.04325727,  0.04165056,\n",
      "       -0.09479519,  0.04819943,  0.0043376 ,  0.02920211, -0.09145907,\n",
      "        0.19575259,  0.02443421,  0.04926302, -0.03577467,  0.00250712,\n",
      "       -0.07623282,  0.02816669,  0.06048211, -0.08226568, -0.14728905,\n",
      "        0.01609571, -0.00331404, -0.02270802,  0.04396421, -0.01816026,\n",
      "       -0.05329216, -0.03391641,  0.03936942, -0.08635408, -0.03828816],\n",
      "      dtype=float32), array([7.3604980e+02, 1.9381289e+01, 9.2006607e+01, 6.5717859e+02,\n",
      "       3.5717368e+00, 5.4868898e+00, 6.5911775e+00, 1.9642767e+00,\n",
      "       1.7361425e+01, 6.8064004e-01, 7.7809273e+01, 8.2660559e+02,\n",
      "       2.5192083e+03, 2.9527609e+02, 7.0583015e-03, 2.0421235e-01,\n",
      "       5.1822841e-01, 5.8114745e-02, 2.1959625e-01, 1.7759426e-02,\n",
      "       3.8960434e+02, 2.5756203e+01, 1.0755109e+02, 8.8988586e+02,\n",
      "       1.1286726e+01, 2.4051636e+01, 2.7660074e+01, 1.0028986e+01,\n",
      "       3.1068443e+01, 1.8593919e+00], dtype=float32), array([5.4996935e+06, 1.6926985e+01, 5.5888824e+02, 1.1930676e+05,\n",
      "       3.3610046e+02, 7.6509973e+02, 9.5119202e+02, 2.2052219e+02,\n",
      "       2.7424255e+03, 3.6792442e+01, 7.1731945e+04, 6.5932731e+05,\n",
      "       2.6786142e+06, 1.9778919e+06, 8.4614130e-06, 3.1445715e+00,\n",
      "       3.4766125e+01, 4.3019691e-01, 4.0699763e+00, 7.5420454e-02,\n",
      "       3.0350525e+06, 3.5516838e+01, 1.0741895e+03, 3.1751750e+05,\n",
      "       1.3453147e+03, 8.2659697e+03, 1.2854046e+04, 1.6430038e+03,\n",
      "       7.7863682e+03, 1.6260654e+02], dtype=float32)]\n",
      "4\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))\n",
    "pesos1 = classificador.layers[1].get_weights()\n",
    "pesos2 = classificador.layers[2].get_weights()\n",
    "\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "previsoes = (previsoes > 0.5)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "\n",
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0d0b5-68e7-4de8-984e-c9c222c8e52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
